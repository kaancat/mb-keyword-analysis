# 9.4 Understanding AI Confidence

Now let's address how we think about understanding artificial intelligence.Confidence.There's labeled data like your conversion data, your profit metrics, audience signals, shopping feedata, engagement data.Those are all those are all bits of information that have an associated definition or associated bucketthat we could place them in.So for example, conversion data that could be you have a conversion rate of 10%.You have an average order value of $30.You have your average profit is is is 6%.It's a metric with an attached label.Then you have prompts.Prompts are restraints and they're the controls of the machine.So you have bidding audience targets, keywords, locations, ad schedules, budgets.Right.These are all the different levers and buttons that you could pull to make the machine learn and actdifferently.Retargeting is a good example of where a prompt and label data can overlap.Retargeting requires label data.It requires understanding our actual website visitors.And it also requires an audience target.So I'm telling the machine use this structured label data from my 30 day visitors.Anybody who's been on my site in the last 30 days that's labeled structured data, and then with thisbudget, only show ads to those people.That's audience targeting and bidding.So label data and prompts are how we fine tune machine learning.Now you might be wondering, can I just set my target Roas and be done?This all sounds so complicated.Um, let me just give Google a bunch of keywords, set a target row as of 300%, and walk away.So no.And there's a few reasons for that one.Data deficiencies.In a perfect world, we'd have more than enough conversion data to inform the AI.But but at the end of the day, we don't.We just don't have enough conversion value to realistically train the model perfectly in the way thatwe just described, because everything that we describe and everything that Google says that they'reattempting to do is in an idealistic world.But we don't live in an idealistic world.And the truth is, you need enormous, enormous amounts of actual conversion data in order to perfectlyor more accurately predict which users are going to convert.Number two is what we call hallucinations inaccurate or misleading predictions based on the AI's limitedunderstanding of context and reliance on historical data.I have a whole separate lecture on this.Why context matters, but what the machine learning is basically attempting to do is say, we're tryingto understand how you're going to behave now based on how you've behaved yesterday and how you behavedin the past.But we don't behave like that.We don't behave today in accordance with patterns that we've behaved yesterday.Now, of course we do in some to some extent, right.So if somebody owns if somebody has owned luxury sports cars for four years, the chances are high thatthey're going to own a luxury sports car for a fifth year.So how we've behaved yesterday can inform how we behave today, which is exactly why smart bidding tendsto work well over time, when it's given enough budget and it's given enough time, but it doesn't alwaysget it right.So you have to be there to use your prompts, understand your label data, understand what informationyou have and what that information means, and understand your prompts and controls how to help themachine make better predictions.And lastly, we have platform and market dynamism.There's just an enormous amount of complexity when it comes to predicting human behavior in dynamicmarkets, in dynamic markets.And that's something that necessitates active management products change, news comes out, weatherchanges, disposable incomes change, competitors drop out, competitors enter, new technologies released,new technology is is cheaper.So all of that dynamism makes it very hard for Google to reliably look at what we've done yesterdayand predict what we're going to do today.You know, just a very easy current example.If Google looks at me, they'll and looks at my behavioral paradigm.They're probably predicting that I'm going to be using Google Search to find information, because that'show I've done things for a long time.But now we're starting to use ChatGPT.So Google's understanding of how I get information doesn't take into context the fact that I'm reallyexcited about this brand new technology.Eventually it will.Eventually, Google's going to see that I'm behaving differently, and they're going to have to tryto they're going to have to eventually figure out what I've replaced Google Search with, why I've replacedGoogle search.When do I decide to use one search engine over another?And what external stimuli in the environment that which is what we call context impacts?When I decide one way versus when I decide another way.And that's something that that a machine learning program like this has to decide.Trillions and trillions of times a day for trillions of micro decisions people are making.So here's an interesting formula that we like to talk about when it comes to understanding how confidentan AI model can actually be.So model stability is really the output of the following.Right.You have your historical accuracy.How right has a model been in the past times.Relevance feedback.So in real time click through rates engagement rates on site.That's that's real time feedback.Whether this user is interacting um, in the way that the model predicted and then data volume overdata variability.How homogeneous or diverse is that data.Data volume is just the sheer amount of data that AI has to learn from.How many clicks, how many searches, how many website visits, how many checkouts, how many form fills.The larger the data set, the better the AI understands user behavior and can pick up on different patterns.So you have these different um, and again, model stability is the consistency of performance overtime and condition across different markets.So when we talk about model stability it's in relationship to Google Ads.We're asking Google predicted that this user or this type of person on this device, this location,on this time of day with all of these other signals when they're confronted, when they search for this,when they when they input this sentence into Google and they are confronted with this product at thisprice, the model converts that there is an above average likelihood for them to convert.So to understand whether or not that that that that's accurate or that's something that we can beginto trust, we have to look at the historical accuracy.And I would say, generally speaking, overall Google has gotten better, our campaigns have gottenmore profitable.And you watch your own campaigns, Google's historical accuracy improves.So Google knows that our model is built roughly well.It doesn't get it right all the time.It doesn't get right.It gets it wrong a lot of the time.But the the the foundational elements seem to be correct.Relevance feedback is okay.Well, I'm making this prediction that we're going to get a click on this ad.Do I get that click.And when I get that click is somebody scrolling or are they bouncing off the page.Are they adding an item to their cart?Google's using all of that real time engagement to inform its model, based on whether or not the realtime engagement is in accordance with what the historical accuracy predicted that engagement to be.And then, of course, to the to the level in which that engagement is trusted is whether or not thatengagement and those those activities have enough volume of similar instances, similar data pointsfor it to be useful for it to be statistically significant.And then if you have, then you look at the data volume, the relevance feedback, the historical accuracy,and then we say, okay, is all this data variable or is it homogeneous.Is it like people.Is it is it something homogeneous would be all right.They're all people in in in diverse locations and they're across the different spectrum of of ages anddifferent genders and different income brackets and so on and so forth.And that's going to impact how Google updates its model.Right?So, so the more homogeneous, the more similar a data set is.The the the less the the less effective that model to predict what will happen with inputs differentthan that homogenous data set.And all of those factors together gives you something what we call model stability.So this is all of this is to say that this is this is complex stuff.And there's a lot going on under the hood.But if you could, especially if you're dealing with clients, if you could talk about AI confidencewith clients and use this concept to to show a client why a this is a good bet to take and b it's goingto take some time and investment and C it's never it's not always going to be perfect.You're going to have days that are wildly swinging up and down.In fact, as Google and Meta have adopted more, um, more artificial intelligence and machine learning,we've seen more variability and more swings in performance on a day to day basis than before, but thatmakes sense when you understand how the under the hood AI infrastructure is built.Hallucinations can occur when automated systems generate misleading or inaccurate predictions or recommendations.So we've discussed sort of this this concept of hallucinations and getting it wrong.But one misleading performance predictions, inaccurate targeting suggestions, keyword recommendationsthat are wrong.You'll see that in your Google Ads account all the time, and four bit optimizations that might be incorrect.Overfitting occurs when a model is too closely fit to the training data, capturing noise or randomfluctuations, rather than the underlying patterns that are supposed to guide decision making.Those are all different elements that could go into what is called a hallucination in AI terms, whichis why active management is still required.In the next lesson, we're going to talk about some practical applications for using and putting thisbetter understanding of machine learning to work inside your performance.Media campaigns.